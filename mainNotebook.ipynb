{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "import os \n",
    "import src.mapping as m\n",
    "import src.classes\n",
    "from src.classes.PDFReader import PDFReader as pdf_reader\n",
    "from src.classes.Prompter import Prompter\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "from openpyxl import load_workbook\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of field_to_question: 59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the workbook\n",
    "wb = load_workbook('ESA eval metrics.xlsx')\n",
    "\n",
    "# Select the sheet\n",
    "ws = wb['Sheet1']\n",
    "\n",
    "# Create a dictionary where column A serves as the key and column B as the value\n",
    "field_to_question = {ws.cell(row=i, column=2).value: ws.cell(row=i, column=1).value for i in range(1, ws.max_row+1)}\n",
    "print(f\"length of field_to_question: {len(field_to_question)}\")\n",
    "# pprint(field_to_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "{'3.4', '7.0', '2.3', '2.4', '4.2', '6.1', '3.1', '3.5', '6.3', '2.2', '2.1', '6.2', '1.5', '4.1', '5.1', '1.0', '3.3', '5.2', '6.0', '3.2', '6.4'}\n",
      "num_datafields: 488\n",
      "length of matches_dict: 58\n"
     ]
    }
   ],
   "source": [
    "datafields = m.execute()\n",
    "num_datafields = 0\n",
    "matches_dict = {}\n",
    "for items in sorted(datafields.items()):\n",
    "  subsection = items[0]\n",
    "  questions = items[1]\n",
    "  num_datafields += len(questions)\n",
    "  for field, question in questions.items():\n",
    "    if field in field_to_question.keys():\n",
    "      # print(f\"question: {question}\")\n",
    "      # print(f\"field = {field}\")\n",
    "      matches_dict[field] = question\n",
    "      \n",
    "print(f\"num_datafields: {num_datafields}\")\n",
    "print(f\"length of matches_dict: {len(matches_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"phi3\", temperature=0, num_predict=40, top_k=5, top_p=.3, mirostat_tau=0, format=\"json\")\n",
    "context_system_prompt = \"\"\"Retrieve the datafield defined in input within the context given. \n",
    "Anything legal can be found in the context and chat history.\n",
    "If you cannot answer the question with the context, respond with N/A.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "{input} is the prompt.\n",
    "Again, if you cannot answer the question respond N/A.\n",
    "Simply respond with only the answer that matches the datafield.\n",
    "There must only be one JSON object.\n",
    "Do not include the datafield in your response. Keep the key for the json exactly the same as the input.\n",
    "\"\"\"\n",
    "# ChatPromptTemplate.from_template()\n",
    "\n",
    "context_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", context_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True)#,\n",
    "        ,(\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "qa_system_prompt = context_system_prompt #\"\"\"Reading through a PDF and giving only the answers found within it. If you do not know an answer, you respond N/A.\"\"\"\n",
    "\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\")#,\n",
    "        ,(\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "qa_document_chain = qa_prompt | llm | JsonOutputParser()\n",
    "history_aware_retriever = context_prompt | llm | JsonOutputParser()\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    history_aware_retriever, qa_document_chain)\n",
    "\n",
    "chat_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_path = 'pdf_new_641566.pdf'\n",
    "subsection_dict = pdf_reader().process_file(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dict = {}\n",
    "\n",
    "for subsection, field_to_questions in sorted(datafields.items()):\n",
    "    subsection_answers = {}\n",
    "    if subsection:      # (subsection == *selected section*)\n",
    "        section_number = subsection.split('.')[0]\n",
    "        for field, question in field_to_questions.items():\n",
    "            try:\n",
    "                subsection_context = subsection_dict[section_number][subsection]\n",
    "                # -----------------------------INVOKE LLM---------------------------------------\n",
    "                output_dict = retrieval_chain.invoke({'input':question, 'context': [Document(page_content=subsection_context)], \n",
    "                                                    'chat_history':chat_history})\n",
    "                \n",
    "                # -----------------------------INVOKE LLM---------------------------------------\n",
    "                key = list(output_dict['answer'].keys())[0]\n",
    "                subsection_answers[question] = output_dict['answer'][key]\n",
    "                answer = subsection_answers[question]\n",
    "                print(f'> Answer: {answer}\\n')\n",
    "            except Exception as e:\n",
    "                print(\"!!!!!!!!!!!!!!!\")\n",
    "                print(f'Error in Subsection {subsection}: {e}')\n",
    "                print(\"!!!!!!!!!!!!!!!\")\n",
    "    answers_dict[subsection] = subsection_answers\n",
    "# Write to JSON\n",
    "pdf_name = pdf_path.split('.')[0]\n",
    "with open(f\"data/processed/{pdf_name}.json\", \"w\") as outfile: \n",
    "    json.dump(answers_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
